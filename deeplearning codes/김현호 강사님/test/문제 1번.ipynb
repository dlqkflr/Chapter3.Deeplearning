{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST 이미지를 아래 규격의 신경망을 이용하여 0~9 까지의 숫자로 분류하시오.\n",
    "- 첫 번째 중간층 : Dense , 뉴런 64개 relu\n",
    "- 두 번째 중간층 : Dense , 뉴런 16개 relu\n",
    "- 출력층은 분류 목적에 맞게 적절히 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28), (60000,), (10000, 28, 28), (10000,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "X_train = X_train.reshape(-1, 28*28)/255.\n",
    "X_test = X_test.reshape(-1, 28*28)/255.\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 784), (60000, 10), (10000, 784), (10000, 10))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(64, input_shape=(784,) ,activation = 'relu' ))\n",
    "model.add(Dense(16, activation = 'relu' ))\n",
    "model.add(Dense(10, activation = 'softmax' ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Anaconda3\\lib\\site-packages\\keras\\optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 64)                50240     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16)                1040      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                170       \n",
      "=================================================================\n",
      "Total params: 51,450\n",
      "Trainable params: 51,450\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From C:\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/20\n",
      "48000/48000 [==============================] - 2s 45us/step - loss: 0.5252 - acc: 0.8529 - val_loss: 0.2449 - val_acc: 0.9325\n",
      "Epoch 2/20\n",
      "48000/48000 [==============================] - 1s 16us/step - loss: 0.2152 - acc: 0.9394 - val_loss: 0.1811 - val_acc: 0.9492\n",
      "Epoch 3/20\n",
      "48000/48000 [==============================] - 1s 16us/step - loss: 0.1614 - acc: 0.9545 - val_loss: 0.1540 - val_acc: 0.9568\n",
      "Epoch 4/20\n",
      "48000/48000 [==============================] - 1s 16us/step - loss: 0.1322 - acc: 0.9620 - val_loss: 0.1390 - val_acc: 0.9611\n",
      "Epoch 5/20\n",
      "48000/48000 [==============================] - 1s 16us/step - loss: 0.1118 - acc: 0.9675 - val_loss: 0.1296 - val_acc: 0.9633\n",
      "Epoch 6/20\n",
      "48000/48000 [==============================] - 1s 16us/step - loss: 0.0963 - acc: 0.9716 - val_loss: 0.1273 - val_acc: 0.9614\n",
      "Epoch 7/20\n",
      "48000/48000 [==============================] - 1s 16us/step - loss: 0.0847 - acc: 0.9762 - val_loss: 0.1194 - val_acc: 0.9650\n",
      "Epoch 8/20\n",
      "48000/48000 [==============================] - 1s 16us/step - loss: 0.0738 - acc: 0.9786 - val_loss: 0.1188 - val_acc: 0.9643\n",
      "Epoch 9/20\n",
      "48000/48000 [==============================] - 1s 16us/step - loss: 0.0666 - acc: 0.9805 - val_loss: 0.1098 - val_acc: 0.9692\n",
      "Epoch 10/20\n",
      "48000/48000 [==============================] - 1s 16us/step - loss: 0.0597 - acc: 0.9828 - val_loss: 0.1082 - val_acc: 0.9675\n",
      "Epoch 11/20\n",
      "48000/48000 [==============================] - 1s 16us/step - loss: 0.0539 - acc: 0.9839 - val_loss: 0.1088 - val_acc: 0.9683\n",
      "Epoch 12/20\n",
      "48000/48000 [==============================] - 1s 16us/step - loss: 0.0480 - acc: 0.9862 - val_loss: 0.1188 - val_acc: 0.9661\n",
      "Epoch 13/20\n",
      "48000/48000 [==============================] - 1s 16us/step - loss: 0.0434 - acc: 0.9871 - val_loss: 0.1076 - val_acc: 0.9701\n",
      "Epoch 14/20\n",
      "48000/48000 [==============================] - 1s 16us/step - loss: 0.0393 - acc: 0.9891 - val_loss: 0.1057 - val_acc: 0.9708\n",
      "Epoch 15/20\n",
      "48000/48000 [==============================] - 1s 16us/step - loss: 0.0356 - acc: 0.9894 - val_loss: 0.1046 - val_acc: 0.9715\n",
      "Epoch 16/20\n",
      "48000/48000 [==============================] - 1s 16us/step - loss: 0.0318 - acc: 0.9911 - val_loss: 0.1087 - val_acc: 0.9696\n",
      "Epoch 17/20\n",
      "48000/48000 [==============================] - 1s 16us/step - loss: 0.0297 - acc: 0.9913 - val_loss: 0.1133 - val_acc: 0.9691\n",
      "Epoch 18/20\n",
      "48000/48000 [==============================] - 1s 16us/step - loss: 0.0266 - acc: 0.9925 - val_loss: 0.1119 - val_acc: 0.9697\n",
      "Epoch 19/20\n",
      "48000/48000 [==============================] - 1s 16us/step - loss: 0.0257 - acc: 0.9929 - val_loss: 0.1118 - val_acc: 0.9716\n",
      "Epoch 20/20\n",
      "48000/48000 [==============================] - 1s 16us/step - loss: 0.0216 - acc: 0.9943 - val_loss: 0.1172 - val_acc: 0.9700\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, batch_size=128, epochs=20,\n",
    "                    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(64, input_shape=(784,) ,activation = 'relu' ))\n",
    "model.add(Dense(16, activation = 'relu' ))\n",
    "model.add(Dense(10, activation = 'softmax' ))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/15\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.5638 - acc: 0.8403 - val_loss: 0.2383 - val_acc: 0.9354\n",
      "Epoch 2/15\n",
      "48000/48000 [==============================] - 1s 16us/step - loss: 0.2160 - acc: 0.9386 - val_loss: 0.1777 - val_acc: 0.9492\n",
      "Epoch 3/15\n",
      "48000/48000 [==============================] - 1s 16us/step - loss: 0.1620 - acc: 0.9537 - val_loss: 0.1554 - val_acc: 0.9564\n",
      "Epoch 4/15\n",
      "48000/48000 [==============================] - 1s 17us/step - loss: 0.1334 - acc: 0.9614 - val_loss: 0.1362 - val_acc: 0.9603\n",
      "Epoch 5/15\n",
      "48000/48000 [==============================] - 1s 17us/step - loss: 0.1119 - acc: 0.9686 - val_loss: 0.1297 - val_acc: 0.9648\n",
      "Epoch 6/15\n",
      "48000/48000 [==============================] - 1s 17us/step - loss: 0.0986 - acc: 0.9714 - val_loss: 0.1285 - val_acc: 0.9627\n",
      "Epoch 7/15\n",
      "48000/48000 [==============================] - 1s 17us/step - loss: 0.0866 - acc: 0.9746 - val_loss: 0.1225 - val_acc: 0.9653\n",
      "Epoch 8/15\n",
      "48000/48000 [==============================] - 1s 16us/step - loss: 0.0779 - acc: 0.9772 - val_loss: 0.1190 - val_acc: 0.9650\n",
      "Epoch 9/15\n",
      "48000/48000 [==============================] - 1s 17us/step - loss: 0.0685 - acc: 0.9802 - val_loss: 0.1137 - val_acc: 0.9682\n",
      "Epoch 10/15\n",
      "48000/48000 [==============================] - 1s 17us/step - loss: 0.0604 - acc: 0.9827 - val_loss: 0.1117 - val_acc: 0.9673\n",
      "Epoch 11/15\n",
      "48000/48000 [==============================] - 1s 17us/step - loss: 0.0556 - acc: 0.9836 - val_loss: 0.1125 - val_acc: 0.9706\n",
      "Epoch 12/15\n",
      "48000/48000 [==============================] - 1s 17us/step - loss: 0.0500 - acc: 0.9856 - val_loss: 0.1111 - val_acc: 0.9700\n",
      "Epoch 13/15\n",
      "48000/48000 [==============================] - 1s 17us/step - loss: 0.0443 - acc: 0.9871 - val_loss: 0.1139 - val_acc: 0.9703\n",
      "Epoch 14/15\n",
      "48000/48000 [==============================] - 1s 17us/step - loss: 0.0404 - acc: 0.9879 - val_loss: 0.1134 - val_acc: 0.9702\n",
      "Epoch 15/15\n",
      "48000/48000 [==============================] - 1s 17us/step - loss: 0.0364 - acc: 0.9894 - val_loss: 0.1116 - val_acc: 0.9705\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, batch_size=128, epochs=15,\n",
    "                    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_y = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_y = model.predict_classes(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9731"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(y_test.argmax(axis=1) == pred_y).mean() # accuracy for test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
